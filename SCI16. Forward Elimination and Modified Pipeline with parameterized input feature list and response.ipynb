{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>220821</td>\n",
       "      <td>142313.0</td>\n",
       "      <td>2.228370</td>\n",
       "      <td>-1.480047</td>\n",
       "      <td>-1.875627</td>\n",
       "      <td>-1.777910</td>\n",
       "      <td>-0.549483</td>\n",
       "      <td>-0.428852</td>\n",
       "      <td>-0.635462</td>\n",
       "      <td>-0.225445</td>\n",
       "      <td>-1.665705</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.287575</td>\n",
       "      <td>-0.532184</td>\n",
       "      <td>0.042820</td>\n",
       "      <td>-1.136561</td>\n",
       "      <td>-0.002225</td>\n",
       "      <td>-0.195530</td>\n",
       "      <td>-0.039929</td>\n",
       "      <td>-0.070095</td>\n",
       "      <td>84.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174274</td>\n",
       "      <td>121846.0</td>\n",
       "      <td>1.935030</td>\n",
       "      <td>0.573142</td>\n",
       "      <td>-0.904663</td>\n",
       "      <td>3.502975</td>\n",
       "      <td>0.898790</td>\n",
       "      <td>0.647228</td>\n",
       "      <td>0.111386</td>\n",
       "      <td>0.051637</td>\n",
       "      <td>-1.256962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167848</td>\n",
       "      <td>0.550296</td>\n",
       "      <td>0.057251</td>\n",
       "      <td>0.359922</td>\n",
       "      <td>0.173700</td>\n",
       "      <td>0.063507</td>\n",
       "      <td>-0.038921</td>\n",
       "      <td>-0.056773</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136833</td>\n",
       "      <td>81892.0</td>\n",
       "      <td>-0.957640</td>\n",
       "      <td>0.866259</td>\n",
       "      <td>1.690685</td>\n",
       "      <td>-0.242409</td>\n",
       "      <td>0.069591</td>\n",
       "      <td>-0.387829</td>\n",
       "      <td>0.454028</td>\n",
       "      <td>-0.153593</td>\n",
       "      <td>-0.488368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009150</td>\n",
       "      <td>0.030008</td>\n",
       "      <td>-0.133822</td>\n",
       "      <td>0.176217</td>\n",
       "      <td>-0.040002</td>\n",
       "      <td>1.135290</td>\n",
       "      <td>-0.375523</td>\n",
       "      <td>0.062362</td>\n",
       "      <td>3.84</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170388</td>\n",
       "      <td>120156.0</td>\n",
       "      <td>0.935988</td>\n",
       "      <td>-1.471801</td>\n",
       "      <td>-3.120871</td>\n",
       "      <td>0.725920</td>\n",
       "      <td>1.108254</td>\n",
       "      <td>1.298939</td>\n",
       "      <td>0.600813</td>\n",
       "      <td>0.226943</td>\n",
       "      <td>0.532865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.211974</td>\n",
       "      <td>-0.184652</td>\n",
       "      <td>-0.357264</td>\n",
       "      <td>-1.091420</td>\n",
       "      <td>-0.127987</td>\n",
       "      <td>-0.266858</td>\n",
       "      <td>-0.035785</td>\n",
       "      <td>0.060734</td>\n",
       "      <td>510.36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>264233</td>\n",
       "      <td>161327.0</td>\n",
       "      <td>-0.252903</td>\n",
       "      <td>1.086682</td>\n",
       "      <td>-0.394310</td>\n",
       "      <td>-0.717875</td>\n",
       "      <td>0.440427</td>\n",
       "      <td>-0.730572</td>\n",
       "      <td>0.677892</td>\n",
       "      <td>0.258984</td>\n",
       "      <td>-0.180641</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.261435</td>\n",
       "      <td>-0.712290</td>\n",
       "      <td>0.052698</td>\n",
       "      <td>-0.721858</td>\n",
       "      <td>-0.357179</td>\n",
       "      <td>0.186786</td>\n",
       "      <td>0.118245</td>\n",
       "      <td>0.028695</td>\n",
       "      <td>12.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "220821  142313.0  2.228370 -1.480047 -1.875627 -1.777910 -0.549483 -0.428852   \n",
       "174274  121846.0  1.935030  0.573142 -0.904663  3.502975  0.898790  0.647228   \n",
       "136833   81892.0 -0.957640  0.866259  1.690685 -0.242409  0.069591 -0.387829   \n",
       "170388  120156.0  0.935988 -1.471801 -3.120871  0.725920  1.108254  1.298939   \n",
       "264233  161327.0 -0.252903  1.086682 -0.394310 -0.717875  0.440427 -0.730572   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "220821 -0.635462 -0.225445 -1.665705  ... -0.287575 -0.532184  0.042820   \n",
       "174274  0.111386  0.051637 -1.256962  ...  0.167848  0.550296  0.057251   \n",
       "136833  0.454028 -0.153593 -0.488368  ...  0.009150  0.030008 -0.133822   \n",
       "170388  0.600813  0.226943  0.532865  ...  0.211974 -0.184652 -0.357264   \n",
       "264233  0.677892  0.258984 -0.180641  ... -0.261435 -0.712290  0.052698   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "220821 -1.136561 -0.002225 -0.195530 -0.039929 -0.070095   84.99      0  \n",
       "174274  0.359922  0.173700  0.063507 -0.038921 -0.056773    0.00      0  \n",
       "136833  0.176217 -0.040002  1.135290 -0.375523  0.062362    3.84      0  \n",
       "170388 -1.091420 -0.127987 -0.266858 -0.035785  0.060734  510.36      0  \n",
       "264233 -0.721858 -0.357179  0.186786  0.118245  0.028695   12.98      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import sklearn\n",
    "import imblearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# reading in CSV\n",
    "df = pd.read_csv('creditcard.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Time', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb \n",
    "from sklearn import metrics\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "import math\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "class modelpipeline:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def run_model(self, df, varlist, response, testratio, standardize, sampletype, modelname, text, CV):\n",
    "        varlist.append(response)\n",
    "        df = df[varlist]\n",
    "        if standardize == True:\n",
    "            df = self.standardize(df)\n",
    "        if sampletype == 'smote':\n",
    "            X_train, X_test, y_train, y_test = sampling.smote_oversample(df, testratio, response)\n",
    "        elif sampletype == 'adasyn':\n",
    "            X_train, X_test, y_train, y_test = sampling.adasyn_oversample(df, testratio, response)\n",
    "        else:\n",
    "            X_train, X_test, y_train, y_test = sampling.naive_oversample(df, testratio, response)\n",
    "        store = self.build_model(X_train, X_test, y_train, y_test, text, modelname, CV)\n",
    "        # test model with all actual fraud results\n",
    "        store['actual_accuracy'] = evaluate.actual_acc(df, store['model'], response)\n",
    "        return store\n",
    "    \n",
    "    def build_model(self, X_train, X_test, y_train, y_test, text, modelname, CV):\n",
    "        if modelname == 'LogisticRegression':\n",
    "            if CV == True:\n",
    "                param_grid = dict(C=[0.8,1,1.2], max_iter=[300], solver=['liblinear'])\n",
    "                LogRegression = LogisticRegression()\n",
    "                model = GridSearchCV(LogRegression, param_grid, cv=5, scoring='f1', verbose=10)\n",
    "                model.fit(X_train,y_train)\n",
    "                print(\"Best f1 score: \" + str(model.best_score_))\n",
    "                print(\"Best parameters: \" + str(model.best_params_))\n",
    "            else:\n",
    "                model = LogisticRegression(max_iter=300, C=0.8, solver='liblinear')\n",
    "                model.fit(X_train,y_train)\n",
    "        elif modelname == 'XGBoost':\n",
    "            if CV == True:\n",
    "                end_value = math.ceil(math.sqrt(X_train.shape[1]))\n",
    "                start_value = end_value - 2       \n",
    "                # treedepth = list(range(start_value, end_value+1, 2))\n",
    "                param_grid = dict(n_estimators=[100], max_depth=[end_value])\n",
    "                GradientBoost = GradientBoostingClassifier()\n",
    "                model = GridSearchCV(GradientBoost, param_grid, cv=5, scoring='f1', verbose=10)\n",
    "                model.fit(X_train,y_train)\n",
    "                print(\"Best f1 score: \" + str(model.best_score_))\n",
    "                print(\"Best parameters: \" + str(model.best_params_))\n",
    "                \n",
    "                # Testing out xgb.cv (incomplete)\n",
    "                # model = xgb.XGBClassifier(seed=42, nthread=1, max_depth=start_value, n_estimators=100, random_state=42)\n",
    "                # xgb_param = dict(n_estimators=100, max_depth=end_value)\n",
    "                # xgtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "                # model = xgb.cv(params=xgb_param, dtrain=xgtrain, nfold=5, metrics='auc')\n",
    "                # model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], verbose=5)\n",
    "                \n",
    "                # USING kfold library to do kfold testing on XGBoost:\n",
    "                # cross_val_score using kfold does not fit the model, so nothing can be predicted\n",
    "                # it's just to see the results but the model has to be fitted later on\n",
    "                # kfold = KFold(n_splits=3, random_state=42)\n",
    "                # print(kfold)\n",
    "                # scores = cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "                # print(\"CV Accuracy: %.2f%% (%.2f%%)\" % (scores.mean()*100, scores.std()*100))\n",
    "            else:\n",
    "                model = xgb.XGBClassifier(seed=42, nthread=1, max_depth=math.ceil(math.sqrt(X_train.shape[1])),\n",
    "                                          n_estimators=100, random_state=42)\n",
    "                model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], verbose=5)\n",
    "        elif modelname == 'RandomForest':\n",
    "            if CV == True:\n",
    "                start_value = math.ceil(math.sqrt(X_train.shape[1]))\n",
    "                end_value = start_value + 11         \n",
    "                treedepth = list(range(start_value, end_value, 5))\n",
    "                param_grid = dict(random_state=[42], max_depth=treedepth, n_estimators=[100,150])\n",
    "                RFC = RandomForestClassifier()\n",
    "                model = GridSearchCV(RFC, param_grid, cv=5, scoring='f1', verbose=10)\n",
    "                model.fit(X_train,y_train)\n",
    "                print(\"Best f1 score: \" + str(model.best_score_))\n",
    "                print(\"Best parameters: \" + str(model.best_params_))\n",
    "            else:\n",
    "                treedepth = math.ceil(math.sqrt(X_train.shape[1]))\n",
    "                model = RandomForestClassifier(random_state=42, max_depth=treedepth, n_estimators=150)\n",
    "                model.fit(X_train,y_train)\n",
    "        else:\n",
    "            # Parameters based on gridsearchcv of modelname = logistic regresion\n",
    "            # Leave parameter blank for modelname to run this instance of logistic regression\n",
    "            model = LogisticRegression(C=0.8, max_iter=300, solver='liblinear')\n",
    "            model.fit(X_train,y_train)\n",
    "        \n",
    "        y_predict = model.predict(X_test)\n",
    "        results = evaluate.model_results(y_test, y_predict, text)\n",
    "        store = {\"model\": model, \"X_train\": X_train, \"X_test\": X_test, \"y_train\": y_train, \n",
    "                 \"y_test\": y_test, \"results\": results}\n",
    "        print(\"Model fitting and results are complete!\")\n",
    "        return store\n",
    "    \n",
    "    def standardize(self, df):\n",
    "        # Variables already standardized except for Amount\n",
    "        # columns = df.columns.values.tolist()\n",
    "        # columns.remove(response)\n",
    "        for column in ['Amount']:\n",
    "            df[column] = (df[column] - df[column].mean()) / df[column].std()\n",
    "        return df\n",
    "\n",
    "class sampling:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    @staticmethod\n",
    "    def naive_oversample(df, testratio, response):\n",
    "        X = df.drop([response], axis=1)\n",
    "        y = df[response]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testratio, random_state=41)\n",
    "        ros = RandomOverSampler(random_state=42)\n",
    "        X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "        # train test split keeps X_test and y_test as pd series, oversampler converts X_train, y_train to numpy\n",
    "        # Convert all to numpy array for XGBoost to not have bugs\n",
    "        X_test = X_test.values\n",
    "        y_test = y_test.values\n",
    "        print(\"Oversampling is complete!\")\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    @staticmethod\n",
    "    def smote_oversample(df, testratio, response):\n",
    "        X = df.drop([response], axis=1)\n",
    "        y = df[response]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testratio, random_state=41)\n",
    "        X_train, y_train = SMOTE().fit_resample(X_train, y_train)\n",
    "        # train test split keeps X_test and y_test as pd series, oversampler converts X_train, y_train to numpy\n",
    "        # Convert all to numpy array for XGBoost to not have bugs\n",
    "        X_test = X_test.values\n",
    "        y_test = y_test.values\n",
    "        print(\"Number of Xs and Ys for SMOTE:\")\n",
    "        print(sorted(Counter(y_train).items()))\n",
    "        print(\"Oversampling is complete!\")\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    @staticmethod\n",
    "    def adasyn_oversample(df, testratio, response):\n",
    "        X = df.drop([response], axis=1)\n",
    "        y = df[response]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testratio, random_state=41)\n",
    "        X_train, y_train = ADASYN().fit_resample(X_train, y_train)\n",
    "        # train test split keeps X_test and y_test as pd series, oversampler converts X_train, y_train to numpy\n",
    "        # Convert all to numpy array for XGBoost to not have bugs\n",
    "        X_test = X_test.values\n",
    "        y_test = y_test.values\n",
    "        print(\"Number of Xs and Ys for ADASYN:\")\n",
    "        print(sorted(Counter(y_train).items()))\n",
    "        print(\"Oversampling is complete!\")\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "\n",
    "class evaluate:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def model_results(y_test, y_predict, text):\n",
    "        cm = metrics.confusion_matrix(y_test, y_predict)\n",
    "        print(cm)\n",
    "        RFC_CM = pd.DataFrame(cm, ['Actual 0', 'Actual 1'], ['Predict 0', 'Predict 1'])\n",
    "        sns.heatmap(RFC_CM, annot=True, annot_kws={\"size\": 16}, cmap='Greens', linewidths=1, fmt='g')# font size\n",
    "        sns.set(font_scale=1.4)#for label size\n",
    "        plt.title(\"Confusion Matrix for \" + text)\n",
    "\n",
    "        # fix for mpl bug that cuts off top/bottom of seaborn viz\n",
    "        b, t = plt.ylim() \n",
    "        b += 0.5 \n",
    "        t -= 0.5 \n",
    "        plt.ylim(b, t) \n",
    "        plt.show() \n",
    "\n",
    "        accuracy = metrics.accuracy_score(y_test, y_predict)\n",
    "        print('Accuracy: ' + str(accuracy))\n",
    "        sensitivity = cm[1][1] / (cm[1][1] + cm[1][0])\n",
    "        recall = sensitivity\n",
    "        print('Sensitivity: ' + str(sensitivity))\n",
    "        specificity = cm[0][0] / (cm[0][0] + cm[0][1])\n",
    "        print('Specificity: ' + str(specificity))\n",
    "        precision = cm[1][1] / (cm[1][1] + cm[0][1])\n",
    "        print('Precision: ' + str(precision))\n",
    "        f1 = 2 * (recall * precision)/(recall + precision)\n",
    "        print('f1 score: ' + str(f1))\n",
    "        auc = evaluate.ROC(y_test, y_predict, text)\n",
    "        results = {\"accuracy\": accuracy, \"sensitivity\": sensitivity, \"specificity\": specificity, \n",
    "                   \"precision\": precision, \"f1\": f1, \"auc\": auc}\n",
    "        print(\"Model classification metrics have finished calculating!\")\n",
    "        return results\n",
    "    \n",
    "    @staticmethod\n",
    "    def ROC(y_test, y_predict, text):\n",
    "        # IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
    "        auc = metrics.roc_auc_score(y_test, y_predict)\n",
    "        print(\"AUC value is: \" + str(auc))\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test, y_predict)\n",
    "        plt.plot(fpr, tpr)\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.0])\n",
    "        plt.title('ROC curve for ' + text)\n",
    "        plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "        plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "        plt.grid(True)\n",
    "        return auc\n",
    "\n",
    "    @staticmethod\n",
    "    def actual_acc(df, model, response):\n",
    "        allpositive = df[df[response] == 1].copy()\n",
    "        x_positive = allpositive.drop([response], axis=1)\n",
    "        y_positive = allpositive[response]\n",
    "        # Convert to numpy array due to XGBoost model.predict not working well for pandas\n",
    "        x_positive = x_positive.values\n",
    "        y_positive = y_positive.values\n",
    "        y_pospredict = model.predict(x_positive)\n",
    "        accuracy_positive = metrics.accuracy_score(y_positive, y_pospredict)\n",
    "        print(\"Accuracy with all fraud results is \" + str(accuracy_positive * 100) + \"%\")\n",
    "        return accuracy_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpipeline = modelpipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Xs and Ys for SMOTE:\n",
      "[(0, 227451), (1, 227451)]\n",
      "Oversampling is complete!\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = sampling.smote_oversample(df,0.2,'Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227451"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']\n"
     ]
    }
   ],
   "source": [
    "colnames = list(df.columns.values)\n",
    "colnames.remove('Class')\n",
    "print(colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.discrete.discrete_model as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing some functions and tricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1\n",
      "V2\n",
      "V3\n",
      "V4\n",
      "V5\n",
      "V6\n",
      "V7\n",
      "V8\n",
      "V9\n",
      "V10\n",
      "V11\n",
      "V12\n",
      "V13\n",
      "V14\n",
      "V15\n",
      "V16\n",
      "V17\n",
      "V18\n",
      "V19\n",
      "V20\n",
      "V21\n",
      "V22\n",
      "V23\n",
      "V24\n",
      "V25\n",
      "V26\n",
      "V27\n",
      "V28\n",
      "Amount\n",
      "Class\n"
     ]
    }
   ],
   "source": [
    "for colname in df.columns.values:\n",
    "    print(colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(454902, 29)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.95504092e+00, -3.80782711e-01, -3.15012853e-01, ...,\n",
       "         4.51682478e-02, -4.71447917e-02,  9.99000000e+00],\n",
       "       [-4.00975239e-01, -6.26942769e-01,  1.55533881e+00, ...,\n",
       "        -3.70468822e-01, -1.44791686e-01,  4.59000000e+01],\n",
       "       [ 7.25090164e-02,  8.20565650e-01, -5.61350916e-01, ...,\n",
       "         2.06394866e-01,  7.02877702e-02,  1.19900000e+01],\n",
       "       ...,\n",
       "       [-1.46122738e+00, -6.84733284e-01,  7.78663606e-01, ...,\n",
       "        -9.51184036e-02,  4.24592502e-02,  3.56509132e+02],\n",
       "       [-1.18327079e+00, -8.26128280e-02,  1.89729819e+00, ...,\n",
       "         5.95769488e-02, -3.16624987e-01,  4.44247638e+01],\n",
       "       [-4.66966201e+00,  9.11443019e-01, -5.35063863e+00, ...,\n",
       "         7.23760311e-01, -7.81816552e-01,  4.18268030e+01]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:,0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(454902, 29)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00,  1.95504092e+00, -3.80782711e-01, ...,\n",
       "         4.51682478e-02, -4.71447917e-02,  9.99000000e+00],\n",
       "       [ 0.00000000e+00, -4.00975239e-01, -6.26942769e-01, ...,\n",
       "        -3.70468822e-01, -1.44791686e-01,  4.59000000e+01],\n",
       "       [ 0.00000000e+00,  7.25090164e-02,  8.20565650e-01, ...,\n",
       "         2.06394866e-01,  7.02877702e-02,  1.19900000e+01],\n",
       "       ...,\n",
       "       [ 0.00000000e+00, -1.46122738e+00, -6.84733284e-01, ...,\n",
       "        -9.51184036e-02,  4.24592502e-02,  3.56509132e+02],\n",
       "       [ 0.00000000e+00, -1.18327079e+00, -8.26128280e-02, ...,\n",
       "         5.95769488e-02, -3.16624987e-01,  4.44247638e+01],\n",
       "       [ 0.00000000e+00, -4.66966201e+00,  9.11443019e-01, ...,\n",
       "         7.23760311e-01, -7.81816552e-01,  4.18268030e+01]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_x = np.empty((454902,1))\n",
    "np.concatenate((full_x, X_train), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('c', 1000)\n",
      "c\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "# Finding element of dictionary with max value\n",
    "import operator\n",
    "stats = {\"a\":1, \"b\":2, \"c\":1000}\n",
    "print(max(stats.items(), key=operator.itemgetter(1)))\n",
    "print(max(stats.items(), key=operator.itemgetter(1))[0])\n",
    "print(max(stats.items(), key=operator.itemgetter(1))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((1,1)).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(False).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual implementation of forward selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']\n",
      "False\n",
      "i is 0\n",
      "j is 0\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "()\n",
      "False\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.575323\n",
      "         Iterations 7\n",
      "First model trained using feature number 0 with p value of 0\n",
      "Full X:\n",
      "(454902, 1)\n",
      "i is 1\n",
      "j is 1\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 1)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.511706\n",
      "         Iterations 7\n",
      "Features all have p value of 0, using feature number 1\n",
      "i is 2\n",
      "j is 2\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 2)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.449435\n",
      "         Iterations 8\n",
      "Features all have p value of 0, using feature number 2\n",
      "i is 3\n",
      "j is 3\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 3)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.421701\n",
      "         Iterations 8\n",
      "Features all have p value of 0, using feature number 3\n",
      "i is 4\n",
      "j is 4\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 4)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.420453\n",
      "         Iterations 9\n",
      "i is 4\n",
      "j is 5\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 4)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.420351\n",
      "         Iterations 8\n",
      "i is 4\n",
      "j is 6\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 4)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.415400\n",
      "         Iterations 9\n",
      "Features all have p value of 0, using feature number 6\n",
      "i is 5\n",
      "j is 4\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 5)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.414459\n",
      "         Iterations 9\n",
      "i is 5\n",
      "j is 5\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 5)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.414210\n",
      "         Iterations 9\n",
      "i is 5\n",
      "j is 7\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 5)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.415362\n",
      "         Iterations 9\n",
      "i is 5\n",
      "j is 8\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 5)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412636\n",
      "         Iterations 9\n",
      "Features all have p value of 0, using feature number 8\n",
      "i is 6\n",
      "j is 4\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.411805\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 5\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.411662\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 7\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412498\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 9\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.400688\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 10\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.405340\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 11\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.398916\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412530\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 13\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.388913\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412636\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 15\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408969\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 16\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.409203\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 17\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412250\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 18\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412590\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 19\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412578\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 20\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412013\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 21\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412627\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 22\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412562\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 23\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412503\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 24\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412423\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 25\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412547\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 26\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412395\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 27\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412474\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 28\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.376845\n",
      "         Iterations 9\n",
      "Getting new model with min p-values with 6 variables.\n",
      "New model trained using feature number 15 with lowest p values of 6.205335420577937e-262\n",
      "i is 7\n",
      "j is 4\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408761\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 5\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408033\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 7\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408769\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 9\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.399202\n",
      "         Iterations 10\n",
      "i is 7\n",
      "j is 10\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.402730\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 11\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.397522\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408835\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 13\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.387514\n",
      "         Iterations 10\n",
      "i is 7\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408958\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 16\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.407749\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 17\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408958\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 18\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408632\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 19\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408953\n",
      "         Iterations 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 7\n",
      "j is 20\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408473\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 21\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408965\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 22\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408867\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 23\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408796\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 24\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408683\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 25\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408863\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 26\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408757\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 27\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408826\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 28\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.367316\n",
      "         Iterations 9\n",
      "Getting new model with min p-values with 7 variables.\n",
      "New model trained using feature number 28 with lowest p values of 9.499228499425949e-239\n",
      "i is 8\n",
      "j is 4\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 8)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.345673\n",
      "         Iterations 10\n",
      "Features all have p value of 0, using feature number 4\n",
      "i is 9\n",
      "j is 5\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 9)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.343745\n",
      "         Iterations 10\n",
      "Features all have p value of 0, using feature number 5\n",
      "i is 10\n",
      "j is 7\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 10)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.337735\n",
      "         Iterations 10\n",
      "Features all have p value of 0, using feature number 7\n",
      "i is 11\n",
      "j is 9\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 11)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.290338\n",
      "         Iterations 10\n",
      "i is 11\n",
      "j is 10\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 11)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.322491\n",
      "         Iterations 10\n",
      "Features all have p value of 0, using feature number 10\n",
      "i is 12\n",
      "j is 9\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 12)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.284907\n",
      "         Iterations 10\n",
      "i is 12\n",
      "j is 11\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 12)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.303819\n",
      "         Iterations 10\n",
      "i is 12\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 12)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.322490\n",
      "         Iterations 10\n",
      "i is 12\n",
      "j is 13\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 12)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.291220\n",
      "         Iterations 10\n",
      "Features all have p value of 0, using feature number 13\n",
      "i is 13\n",
      "j is 9\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 13)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.272006\n",
      "         Iterations 10\n",
      "i is 13\n",
      "j is 11\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 13)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275543\n",
      "         Iterations 11\n",
      "Features all have p value of 0, using feature number 11\n",
      "i is 14\n",
      "j is 9\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 14)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.254256\n",
      "         Iterations 11\n",
      "i is 14\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 14)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275389\n",
      "         Iterations 11\n",
      "i is 14\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 14)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275412\n",
      "         Iterations 11\n",
      "i is 14\n",
      "j is 16\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 14)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.270002\n",
      "         Iterations 12\n",
      "i is 14\n",
      "j is 17\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 14)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275312\n",
      "         Iterations 11\n",
      "i is 14\n",
      "j is 18\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 14)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274895\n",
      "         Iterations 11\n",
      "i is 14\n",
      "j is 19\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 14)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.261909\n",
      "         Iterations 11\n",
      "Features all have p value of 0, using feature number 19\n",
      "i is 15\n",
      "j is 9\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 15)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.237699\n",
      "         Iterations 11\n",
      "Features all have p value of 0, using feature number 9\n",
      "i is 16\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 16)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.237684\n",
      "         Iterations 11\n",
      "i is 16\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 16)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.237664\n",
      "         Iterations 11\n",
      "i is 16\n",
      "j is 16\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 16)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.223758\n",
      "         Iterations 13\n",
      "Features all have p value of 0, using feature number 16\n",
      "i is 17\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 17)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.223733\n",
      "         Iterations 13\n",
      "i is 17\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 17)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.223645\n",
      "         Iterations 13\n",
      "i is 17\n",
      "j is 17\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 17)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.220652\n",
      "         Iterations 14\n",
      "i is 17\n",
      "j is 18\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 17)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.221769\n",
      "         Iterations 13\n",
      "Features all have p value of 0, using feature number 18\n",
      "i is 18\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 18)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.221762\n",
      "         Iterations 13\n",
      "i is 18\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 18)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.221733\n",
      "         Iterations 13\n",
      "i is 18\n",
      "j is 17\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 18)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.219774\n",
      "         Iterations 14\n",
      "i is 18\n",
      "j is 20\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 18)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.209721\n",
      "         Iterations 13\n",
      "Features all have p value of 0, using feature number 20\n",
      "i is 19\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 19)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.209702\n",
      "         Iterations 13\n",
      "i is 19\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 19)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.209661\n",
      "         Iterations 13\n",
      "i is 19\n",
      "j is 17\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 19)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.205329\n",
      "         Iterations 15\n",
      "i is 19\n",
      "j is 21\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 19)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.208175\n",
      "         Iterations 13\n",
      "i is 19\n",
      "j is 22\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 19)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.189352\n",
      "         Iterations 14\n",
      "Features all have p value of 0, using feature number 22\n",
      "i is 20\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 20)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.189289\n",
      "         Iterations 14\n",
      "i is 20\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 20)\n",
      "True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.189341\n",
      "         Iterations 14\n",
      "i is 20\n",
      "j is 17\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 20)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.187372\n",
      "         Iterations 16\n",
      "i is 20\n",
      "j is 21\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 20)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.185437\n",
      "         Iterations 14\n",
      "Features all have p value of 0, using feature number 21\n",
      "i is 21\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 21)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.185402\n",
      "         Iterations 14\n",
      "i is 21\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 21)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.185420\n",
      "         Iterations 14\n",
      "i is 21\n",
      "j is 17\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 21)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.183687\n",
      "         Iterations 15\n",
      "i is 21\n",
      "j is 23\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 21)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.185431\n",
      "         Iterations 14\n",
      "i is 21\n",
      "j is 24\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 21)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.179650\n",
      "         Iterations 14\n",
      "Features all have p value of 0, using feature number 24\n",
      "i is 22\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 22)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.179634\n",
      "         Iterations 14\n",
      "i is 22\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 22)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.179617\n",
      "         Iterations 14\n",
      "i is 22\n",
      "j is 17\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 22)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.178637\n",
      "         Iterations 15\n",
      "i is 22\n",
      "j is 23\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 22)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.179648\n",
      "         Iterations 14\n",
      "i is 22\n",
      "j is 25\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 22)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.179217\n",
      "         Iterations 14\n",
      "i is 22\n",
      "j is 26\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 22)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.176348\n",
      "         Iterations 14\n",
      "Features all have p value of 0, using feature number 26\n",
      "i is 23\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 23)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.176328\n",
      "         Iterations 14\n",
      "i is 23\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 23)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.176295\n",
      "         Iterations 14\n",
      "i is 23\n",
      "j is 17\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 23)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.175418\n",
      "         Iterations 16\n",
      "i is 23\n",
      "j is 23\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 23)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.176348\n",
      "         Iterations 14\n",
      "i is 23\n",
      "j is 25\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 23)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.176096\n",
      "         Iterations 14\n",
      "i is 23\n",
      "j is 27\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 23)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.173760\n",
      "         Iterations 15\n",
      "Features all have p value of 0, using feature number 27\n",
      "i is 24\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 24)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.173750\n",
      "         Iterations 15\n",
      "i is 24\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 24)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.173723\n",
      "         Iterations 15\n",
      "i is 24\n",
      "j is 17\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 24)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.172663\n",
      "         Iterations 16\n",
      "i is 24\n",
      "j is 23\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 24)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.173760\n",
      "         Iterations 15\n",
      "i is 24\n",
      "j is 25\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 24)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.173478\n",
      "         Iterations 14\n",
      "Getting new model with min p-values with 24 variables.\n",
      "New model trained using feature number 17 with lowest p values of 3.248398781061158e-183\n",
      "i is 25\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 25)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.172650\n",
      "         Iterations 16\n",
      "i is 25\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 25)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.172649\n",
      "         Iterations 16\n",
      "i is 25\n",
      "j is 23\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 25)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.172660\n",
      "         Iterations 16\n",
      "i is 25\n",
      "j is 25\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 25)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.172400\n",
      "         Iterations 16\n",
      "Getting new model with min p-values with 25 variables.\n",
      "New model trained using feature number 25 with lowest p values of 9.067123186509317e-53\n",
      "i is 26\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 26)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.172386\n",
      "         Iterations 16\n",
      "i is 26\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 26)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.172386\n",
      "         Iterations 16\n",
      "i is 26\n",
      "j is 23\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 26)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.172399\n",
      "         Iterations 16\n",
      "Getting new model with min p-values with 26 variables.\n",
      "New model trained using feature number 12 with lowest p values of 0.0002697708380148323\n",
      "i is 27\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 27)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.172369\n",
      "         Iterations 16\n",
      "i is 27\n",
      "j is 23\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 27)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.172384\n",
      "         Iterations 16\n",
      "Getting new model with min p-values with 27 variables.\n",
      "New model trained using feature number 14 with lowest p values of 9.867415806552968e-05\n",
      "i is 28\n",
      "j is 23\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 28)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.172368\n",
      "         Iterations 16\n",
      "Getting new model with min p-values with 28 variables.\n",
      "TERMINATING AS best model trained using feature number 23 with high p value of 0.39338990848652755 above significance level: 0.05\n",
      "['V1', 'V2', 'V3', 'V4', 'V7', 'V9', 'V16', 'Amount', 'V5', 'V6', 'V8', 'V11', 'V14', 'V12', 'V20', 'V10', 'V17', 'V19', 'V21', 'V23', 'V22', 'V25', 'V27', 'V28', 'V18', 'V26', 'V13', 'V15']\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "import statsmodels.discrete.discrete_model as sm\n",
    "\n",
    "# Column names have Time (irrelevant feature) and Class (response) removed\n",
    "colnames = list(df.columns.values)\n",
    "colnames.remove('Class')\n",
    "print(colnames)\n",
    "\n",
    "# Total features to select = k\n",
    "# In each iteration, the current set of n features is concatenated with a new feature not inside current set\n",
    "# It is then sent for training with the logistic regression\n",
    "# The model performance for each feature + current features is evaluated by its highest p value (worst feature)\n",
    "# All highest p values of all feature addition to n features (k-n iterations) are put into a dictionary\n",
    "# Next, the lowest p value out of all the iterations (for n features + 1) is chosen for evaluation\n",
    "# Set significance level, which is compared to the lowest p value of the best model in the current training iteration\n",
    "# If best model in current training iteration of n vars has any vars with p value > sig level, then the model training stops\n",
    "# Because all the different models are worse or equally bad as the current best model, we can terminate selection process\n",
    "# If not, repeat this iteration with now n+1 features and k-n-1 iterations\n",
    "sig_level = 0.05\n",
    "\n",
    "maxcolsnum = X_train.shape[1]\n",
    "full_x = np.array(False)\n",
    "allowed_nums = list(range(maxcolsnum))\n",
    "actual_nums = []\n",
    "actual_vars = []\n",
    "terminate_early = False\n",
    "y = y_train\n",
    "for i in range(maxcolsnum):\n",
    "    # Reset boolean and pval_list\n",
    "    terminate_early = False\n",
    "    pval_list = {}\n",
    "    for j in range(maxcolsnum):\n",
    "        if j in allowed_nums:\n",
    "            # Need to reshape to single column instead of a long array for concating properly\n",
    "            jth_x = X_train[:,j].reshape(-1,1)\n",
    "            print(\"i is \" + str(i))\n",
    "            print(\"j is \" + str(j))\n",
    "            print(\"Jth_x:\")\n",
    "            print(jth_x.shape)\n",
    "            print(\"Full_x:\")\n",
    "            print(full_x.shape)\n",
    "            print(full_x.any())\n",
    "            if full_x.any():\n",
    "                iter_x = np.concatenate((full_x, jth_x), axis=1)\n",
    "            else:\n",
    "                iter_x = jth_x\n",
    "            regressor_OLS = sm.Logit(y_train, iter_x).fit()\n",
    "            # print(\"p value for column number: \" + str(i))\n",
    "            # print(regressor_OLS.pvalues[0])\n",
    "            pval_list[j] = max(regressor_OLS.pvalues)\n",
    "            # Special condition where all the features have p values of 0, directly use these variables for training\n",
    "            if max(regressor_OLS.pvalues) == 0:\n",
    "                if full_x.any():\n",
    "                    full_x = np.concatenate((full_x, jth_x), axis=1)\n",
    "                    allowed_nums.remove(j)\n",
    "                    actual_nums.append(j)\n",
    "                    print(\"Features all have p value of 0, using feature number \" + str(j))\n",
    "                else:\n",
    "                    full_x = jth_x\n",
    "                    allowed_nums.remove(j)\n",
    "                    actual_nums.append(j)\n",
    "                    print(\"First model trained using feature number \" + str(j) + \" with p value of 0\")\n",
    "                    print(\"Full X:\")\n",
    "                    print(full_x.shape)\n",
    "                terminate_early = True\n",
    "                break\n",
    "        else:\n",
    "            continue\n",
    "    if i > 0 and terminate_early == False:\n",
    "        print(\"Getting new model with min p-values with \" + str(len(actual_nums)) + \" variables.\")\n",
    "        max_pval_col = min(pval_list.items(), key=operator.itemgetter(1))[0]\n",
    "        max_pval = pval_list[max_pval_col]\n",
    "        # Need to reshape to single column instead of a long array for concating properly\n",
    "        jth_x = X_train[:,max_pval_col].reshape(-1,1)\n",
    "        if max_pval < sig_level:\n",
    "            if full_x.any():\n",
    "                full_x = np.concatenate((full_x, jth_x), axis=1)\n",
    "                allowed_nums.remove(max_pval_col)\n",
    "                actual_nums.append(max_pval_col)\n",
    "                print(\"New model trained using feature number \" + str(max_pval_col) + \" with lowest p values of \" + str(max_pval))\n",
    "            else:\n",
    "                full_x = jth_x\n",
    "                allowed_nums.remove(max_pval_col)\n",
    "                actual_nums.append(max_pval_col)\n",
    "                print(\"First model trained using feature number \" + str(max_pval_col) + \" with lowest p values of \" + str(max_pval))\n",
    "        else:\n",
    "            print(\"TERMINATING AS best model trained using feature number \" + str(max_pval_col) + \" with high p value of \" + str(max_pval) + \" above significance level: \" + str(sig_level))\n",
    "            break\n",
    "                \n",
    "\n",
    "\n",
    "for k in actual_nums:\n",
    "    actual_vars.append(colnames[k])\n",
    "print(actual_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic forward selection with a dataframe but not in a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']\n",
      "i is 0\n",
      "j is 0\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "()\n",
      "False\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.575323\n",
      "         Iterations 7\n",
      "First model trained using feature number 0 with p value of 0\n",
      "Full X:\n",
      "(454902, 1)\n",
      "i is 1\n",
      "j is 1\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 1)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.511706\n",
      "         Iterations 7\n",
      "Features all have p value of 0, using feature number 1\n",
      "i is 2\n",
      "j is 2\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 2)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.449435\n",
      "         Iterations 8\n",
      "Features all have p value of 0, using feature number 2\n",
      "i is 3\n",
      "j is 3\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 3)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.421701\n",
      "         Iterations 8\n",
      "Features all have p value of 0, using feature number 3\n",
      "i is 4\n",
      "j is 4\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 4)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.420453\n",
      "         Iterations 9\n",
      "i is 4\n",
      "j is 5\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 4)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.420351\n",
      "         Iterations 8\n",
      "i is 4\n",
      "j is 6\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 4)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.415400\n",
      "         Iterations 9\n",
      "Features all have p value of 0, using feature number 6\n",
      "i is 5\n",
      "j is 4\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 5)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.414459\n",
      "         Iterations 9\n",
      "i is 5\n",
      "j is 5\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 5)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.414210\n",
      "         Iterations 9\n",
      "i is 5\n",
      "j is 7\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 5)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.415362\n",
      "         Iterations 9\n",
      "i is 5\n",
      "j is 8\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 5)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412636\n",
      "         Iterations 9\n",
      "Features all have p value of 0, using feature number 8\n",
      "i is 6\n",
      "j is 4\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.411805\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 5\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.411662\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 7\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412498\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 9\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.400688\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 10\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.405340\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 11\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.398916\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412530\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 13\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.388913\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412636\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 15\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408969\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 16\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.409203\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 17\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412250\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 18\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412590\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 19\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412578\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 20\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412013\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 21\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412627\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 22\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412562\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 23\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412503\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 24\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412423\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 25\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412547\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 26\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412395\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 27\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412474\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 28\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.376845\n",
      "         Iterations 9\n",
      "Getting new model with min p-values with 6 variables.\n",
      "New model trained using feature number 15 with lowest p values of 6.205335420577937e-262\n",
      "i is 7\n",
      "j is 4\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408761\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 5\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408033\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 7\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408769\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 9\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.399202\n",
      "         Iterations 10\n",
      "i is 7\n",
      "j is 10\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.402730\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 11\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.397522\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408835\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 13\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.387514\n",
      "         Iterations 10\n",
      "i is 7\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408958\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 16\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.407749\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 17\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408958\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 18\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408632\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 19\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408953\n",
      "         Iterations 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 7\n",
      "j is 20\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408473\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 21\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408965\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 22\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408867\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 23\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408796\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 24\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408683\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 25\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408863\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 26\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408757\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 27\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408826\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 28\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.367316\n",
      "         Iterations 9\n",
      "Getting new model with min p-values with 7 variables.\n",
      "New model trained using feature number 28 with lowest p values of 9.499228499425949e-239\n",
      "i is 8\n",
      "j is 4\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 8)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.345673\n",
      "         Iterations 10\n",
      "Features all have p value of 0, using feature number 4\n",
      "i is 9\n",
      "j is 5\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 9)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.343745\n",
      "         Iterations 10\n",
      "Features all have p value of 0, using feature number 5\n",
      "i is 10\n",
      "j is 7\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 10)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.337735\n",
      "         Iterations 10\n",
      "Features all have p value of 0, using feature number 7\n",
      "i is 11\n",
      "j is 9\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 11)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.290338\n",
      "         Iterations 10\n",
      "i is 11\n",
      "j is 10\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 11)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.322491\n",
      "         Iterations 10\n",
      "Features all have p value of 0, using feature number 10\n",
      "i is 12\n",
      "j is 9\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 12)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.284907\n",
      "         Iterations 10\n",
      "i is 12\n",
      "j is 11\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 12)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.303819\n",
      "         Iterations 10\n",
      "i is 12\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 12)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.322490\n",
      "         Iterations 10\n",
      "i is 12\n",
      "j is 13\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 12)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.291220\n",
      "         Iterations 10\n",
      "Features all have p value of 0, using feature number 13\n",
      "i is 13\n",
      "j is 9\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 13)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.272006\n",
      "         Iterations 10\n",
      "i is 13\n",
      "j is 11\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 13)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275543\n",
      "         Iterations 11\n",
      "Features all have p value of 0, using feature number 11\n",
      "i is 14\n",
      "j is 9\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 14)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.254256\n",
      "         Iterations 11\n",
      "i is 14\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 14)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275389\n",
      "         Iterations 11\n",
      "i is 14\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 14)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275412\n",
      "         Iterations 11\n",
      "i is 14\n",
      "j is 16\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 14)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.270002\n",
      "         Iterations 12\n",
      "i is 14\n",
      "j is 17\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 14)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275312\n",
      "         Iterations 11\n",
      "i is 14\n",
      "j is 18\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 14)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274895\n",
      "         Iterations 11\n",
      "i is 14\n",
      "j is 19\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 14)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.261909\n",
      "         Iterations 11\n",
      "Features all have p value of 0, using feature number 19\n",
      "i is 15\n",
      "j is 9\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 15)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.237699\n",
      "         Iterations 11\n",
      "Features all have p value of 0, using feature number 9\n",
      "i is 16\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 16)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.237684\n",
      "         Iterations 11\n",
      "i is 16\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 16)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.237664\n",
      "         Iterations 11\n",
      "i is 16\n",
      "j is 16\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 16)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.223758\n",
      "         Iterations 13\n",
      "Features all have p value of 0, using feature number 16\n",
      "i is 17\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 17)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.223733\n",
      "         Iterations 13\n",
      "i is 17\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 17)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.223645\n",
      "         Iterations 13\n",
      "i is 17\n",
      "j is 17\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 17)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.220652\n",
      "         Iterations 14\n",
      "i is 17\n",
      "j is 18\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 17)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.221769\n",
      "         Iterations 13\n",
      "Features all have p value of 0, using feature number 18\n",
      "i is 18\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 18)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.221762\n",
      "         Iterations 13\n",
      "i is 18\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 18)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.221733\n",
      "         Iterations 13\n",
      "i is 18\n",
      "j is 17\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 18)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.219774\n",
      "         Iterations 14\n",
      "i is 18\n",
      "j is 20\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 18)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.209721\n",
      "         Iterations 13\n",
      "Features all have p value of 0, using feature number 20\n",
      "i is 19\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 19)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.209702\n",
      "         Iterations 13\n",
      "i is 19\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 19)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.209661\n",
      "         Iterations 13\n",
      "i is 19\n",
      "j is 17\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 19)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.205329\n",
      "         Iterations 15\n",
      "i is 19\n",
      "j is 21\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 19)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.208175\n",
      "         Iterations 13\n",
      "i is 19\n",
      "j is 22\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 19)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.189352\n",
      "         Iterations 14\n",
      "Features all have p value of 0, using feature number 22\n",
      "i is 20\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 20)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.189289\n",
      "         Iterations 14\n",
      "i is 20\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 20)\n",
      "True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.189341\n",
      "         Iterations 14\n",
      "i is 20\n",
      "j is 17\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 20)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.187372\n",
      "         Iterations 16\n",
      "i is 20\n",
      "j is 21\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 20)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.185437\n",
      "         Iterations 14\n",
      "Features all have p value of 0, using feature number 21\n",
      "i is 21\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 21)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.185402\n",
      "         Iterations 14\n",
      "i is 21\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 21)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.185420\n",
      "         Iterations 14\n",
      "i is 21\n",
      "j is 17\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 21)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.183687\n",
      "         Iterations 15\n",
      "i is 21\n",
      "j is 23\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 21)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.185431\n",
      "         Iterations 14\n",
      "i is 21\n",
      "j is 24\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 21)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.179650\n",
      "         Iterations 14\n",
      "Features all have p value of 0, using feature number 24\n",
      "i is 22\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 22)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.179634\n",
      "         Iterations 14\n",
      "i is 22\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 22)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.179617\n",
      "         Iterations 14\n",
      "i is 22\n",
      "j is 17\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 22)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.178637\n",
      "         Iterations 15\n",
      "i is 22\n",
      "j is 23\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 22)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.179648\n",
      "         Iterations 14\n",
      "i is 22\n",
      "j is 25\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 22)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.179217\n",
      "         Iterations 14\n",
      "i is 22\n",
      "j is 26\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 22)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.176348\n",
      "         Iterations 14\n",
      "Features all have p value of 0, using feature number 26\n",
      "i is 23\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 23)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.176328\n",
      "         Iterations 14\n",
      "i is 23\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 23)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.176295\n",
      "         Iterations 14\n",
      "i is 23\n",
      "j is 17\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 23)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.175418\n",
      "         Iterations 16\n",
      "i is 23\n",
      "j is 23\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 23)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.176348\n",
      "         Iterations 14\n",
      "i is 23\n",
      "j is 25\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 23)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.176096\n",
      "         Iterations 14\n",
      "i is 23\n",
      "j is 27\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 23)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.173760\n",
      "         Iterations 15\n",
      "Features all have p value of 0, using feature number 27\n",
      "i is 24\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 24)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.173750\n",
      "         Iterations 15\n",
      "i is 24\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 24)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.173723\n",
      "         Iterations 15\n",
      "i is 24\n",
      "j is 17\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 24)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.172663\n",
      "         Iterations 16\n",
      "i is 24\n",
      "j is 23\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 24)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.173760\n",
      "         Iterations 15\n",
      "i is 24\n",
      "j is 25\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 24)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.173478\n",
      "         Iterations 14\n",
      "Getting new model with min p-values with 24 variables.\n",
      "New model trained using feature number 17 with lowest p values of 3.248398781061158e-183\n",
      "i is 25\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 25)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.172650\n",
      "         Iterations 16\n",
      "i is 25\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 25)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.172649\n",
      "         Iterations 16\n",
      "i is 25\n",
      "j is 23\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 25)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.172660\n",
      "         Iterations 16\n",
      "i is 25\n",
      "j is 25\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 25)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.172400\n",
      "         Iterations 16\n",
      "Getting new model with min p-values with 25 variables.\n",
      "New model trained using feature number 25 with lowest p values of 9.067123186509317e-53\n",
      "i is 26\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 26)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.172386\n",
      "         Iterations 16\n",
      "i is 26\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 26)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.172386\n",
      "         Iterations 16\n",
      "i is 26\n",
      "j is 23\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 26)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.172399\n",
      "         Iterations 16\n",
      "Getting new model with min p-values with 26 variables.\n",
      "New model trained using feature number 12 with lowest p values of 0.0002697708380148323\n",
      "i is 27\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 27)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.172369\n",
      "         Iterations 16\n",
      "i is 27\n",
      "j is 23\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 27)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.172384\n",
      "         Iterations 16\n",
      "Getting new model with min p-values with 27 variables.\n",
      "New model trained using feature number 14 with lowest p values of 9.867415806552968e-05\n",
      "i is 28\n",
      "j is 23\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 28)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.172368\n",
      "         Iterations 16\n",
      "Getting new model with min p-values with 28 variables.\n",
      "TERMINATING AS best model trained using feature number 23 with high p value of 0.39338990848652755 above significance level: 0.05\n",
      "Final variables selected:\n",
      "['V1', 'V2', 'V3', 'V4', 'V7', 'V9', 'V16', 'Amount', 'V5', 'V6', 'V8', 'V11', 'V14', 'V12', 'V20', 'V10', 'V17', 'V19', 'V21', 'V23', 'V22', 'V25', 'V27', 'V28', 'V18', 'V26', 'V13', 'V15']\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "import statsmodels.discrete.discrete_model as sm\n",
    "\n",
    "# Column names have Time (irrelevant feature) and Class (response) removed\n",
    "colnames = list(df.columns.values)\n",
    "colnames.remove('Class')\n",
    "print(colnames)\n",
    "\n",
    "# Total features to select = k\n",
    "# In each iteration, the current set of n features is concatenated with a new feature not inside current set\n",
    "# It is then sent for training with the logistic regression\n",
    "# The model performance for each feature + current features is evaluated by its highest p value (worst feature)\n",
    "# All highest p values of all feature addition to n features (k-n iterations) are put into a dictionary\n",
    "# Next, the lowest p value out of all the iterations (for n features + 1) is chosen for evaluation\n",
    "# Set significance level, which is compared to the lowest p value of the best model in the current training iteration\n",
    "# If best model in current training iteration of n vars has any vars with p value > sig level, then the model training stops\n",
    "# Because all the different models are worse or equally bad as the current best model, we can terminate selection process\n",
    "# If not, repeat this iteration with now n+1 features and k-n-1 iterations\n",
    "sig_level = 0.05\n",
    "\n",
    "maxcolsnum = X_train.shape[1]\n",
    "full_x = np.array(False)\n",
    "allowed_nums = {}\n",
    "for i in range(maxcolsnum):\n",
    "    allowed_nums[i] = True\n",
    "actual_nums = []\n",
    "actual_vars = []\n",
    "terminate_early = False\n",
    "y = y_train\n",
    "for i in range(maxcolsnum):\n",
    "    # Reset boolean and pval_list\n",
    "    terminate_early = False\n",
    "    pval_list = {}\n",
    "    for j in range(maxcolsnum):\n",
    "        if allowed_nums[j] == True:\n",
    "            # Need to reshape to single column instead of a long array for concating properly\n",
    "            jth_x = X_train[:,j].reshape(-1,1)\n",
    "            print(\"i is \" + str(i))\n",
    "            print(\"j is \" + str(j))\n",
    "            print(\"Jth_x:\")\n",
    "            print(jth_x.shape)\n",
    "            print(\"Full_x:\")\n",
    "            print(full_x.shape)\n",
    "            print(full_x.any())\n",
    "            if full_x.any():\n",
    "                iter_x = np.concatenate((full_x, jth_x), axis=1)\n",
    "            else:\n",
    "                iter_x = jth_x\n",
    "            regressor_OLS = sm.Logit(y_train, iter_x).fit()\n",
    "            # print(\"p value for column number: \" + str(i))\n",
    "            # print(regressor_OLS.pvalues[0])\n",
    "            pval_list[j] = max(regressor_OLS.pvalues)\n",
    "            # Special condition where all the features have p values of 0, directly use these variables for training\n",
    "            if max(regressor_OLS.pvalues) == 0:\n",
    "                if full_x.any():\n",
    "                    full_x = np.concatenate((full_x, jth_x), axis=1)\n",
    "                    allowed_nums[j] = False\n",
    "                    actual_nums.append(j)\n",
    "                    print(\"Features all have p value of 0, using feature number \" + str(j))\n",
    "                else:\n",
    "                    full_x = jth_x\n",
    "                    allowed_nums[j] = False\n",
    "                    actual_nums.append(j)\n",
    "                    print(\"First model trained using feature number \" + str(j) + \" with p value of 0\")\n",
    "                    print(\"Full X:\")\n",
    "                    print(full_x.shape)\n",
    "                terminate_early = True\n",
    "                break\n",
    "        else:\n",
    "            continue\n",
    "    if i > 0 and terminate_early == False:\n",
    "        print(\"Getting new model with min p-values with \" + str(len(actual_nums)) + \" variables.\")\n",
    "        max_pval_col = min(pval_list.items(), key=operator.itemgetter(1))[0]\n",
    "        max_pval = pval_list[max_pval_col]\n",
    "        # Need to reshape to single column instead of a long array for concating properly\n",
    "        jth_x = X_train[:,max_pval_col].reshape(-1,1)\n",
    "        if max_pval < sig_level:\n",
    "            if full_x.any():\n",
    "                full_x = np.concatenate((full_x, jth_x), axis=1)\n",
    "                allowed_nums[max_pval_col] = False\n",
    "                actual_nums.append(max_pval_col)\n",
    "                print(\"New model trained using feature number \" + str(max_pval_col) + \" with lowest p values of \" + str(max_pval))\n",
    "            else:\n",
    "                full_x = jth_x\n",
    "                allowed_nums[max_pval_col] = False\n",
    "                actual_nums.append(max_pval_col)\n",
    "                print(\"First model trained using feature number \" + str(max_pval_col) + \" with lowest p values of \" + str(max_pval))\n",
    "        else:\n",
    "            print(\"TERMINATING AS best model trained using feature number \" + str(max_pval_col) + \" with high p value of \" + str(max_pval) + \" above significance level: \" + str(sig_level))\n",
    "            break\n",
    "                \n",
    "\n",
    "for k in actual_nums:\n",
    "    actual_vars.append(colnames[k])\n",
    "print('Final variables selected:')\n",
    "print(actual_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward selection\n",
    "## Accepts a dataframe and does train-test split, alongside sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "import statsmodels.discrete.discrete_model as sm\n",
    "\n",
    "def forwardselection(df,testratio,response,removelist,sampling):\n",
    "    if isinstance(removelist, str) == True:\n",
    "        temp_str = removelist\n",
    "        removelist = []\n",
    "        removelist.append(temp_str)\n",
    "    removelist.append(response)\n",
    "    X = df.drop(removelist, axis=1)\n",
    "    y = df[response]\n",
    "    # Get list of column names\n",
    "    colnames = list(X.columns.values)\n",
    "    print(colnames)\n",
    "    \n",
    "    # Start of train-test split and oversampling (if relevant)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testratio, random_state=42)\n",
    "    if sampling.lower() == 'smote':\n",
    "        print(\"SMOTE Oversampling selected..\")\n",
    "        X_train, y_train = SMOTE().fit_resample(X_train, y_train)\n",
    "        # train test split keeps X_test and y_test as pd series, oversampler converts X_train, y_train to numpy\n",
    "        # Convert all to numpy array for XGBoost to not have bugs\n",
    "        X_test = X_test.values\n",
    "        y_test = y_test.values\n",
    "        print(\"Number of Xs and Ys for: \" + str(sampling.upper()))\n",
    "        print(sorted(Counter(y_train).items()))\n",
    "        print(\"Oversampling is complete!\")\n",
    "    elif sampling.lower() == 'naive':\n",
    "        print(\"Naive Oversampling selected..\")\n",
    "        ros = RandomOverSampler(random_state=42)\n",
    "        X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "        # train test split keeps X_test and y_test as pd series, oversampler converts X_train, y_train to numpy\n",
    "        # Convert all to numpy array for XGBoost to not have bugs\n",
    "        X_test = X_test.values\n",
    "        y_test = y_test.values\n",
    "        print(\"Number of Xs and Ys for: \" + str(sampling.upper()))\n",
    "        print(sorted(Counter(y_train).items()))\n",
    "        print(\"Oversampling is complete!\")\n",
    "\n",
    "\n",
    "    # Total features to select = k\n",
    "    # In each iteration, the current set of n features is concatenated with a new feature not inside current set\n",
    "    # It is then sent for training with the logistic regression\n",
    "    # The model performance for each feature + current features is evaluated by its highest p value (worst feature)\n",
    "    # All highest p values of all feature addition to n features (k-n iterations) are put into a dictionary\n",
    "    # Next, the lowest p value out of all the iterations (for n features + 1) is chosen for evaluation\n",
    "    # Set significance level, which is compared to the lowest p value of the best model in the current training iteration\n",
    "    # If best model in current training iteration of n vars has any vars with p value > sig level, then the model training stops\n",
    "    # Because all the different models are worse or equally bad as the current best model, we can terminate selection process\n",
    "    # If not, repeat this iteration with now n+1 features and k-n-1 iterations\n",
    "    sig_level = 0.05\n",
    "\n",
    "    maxcolsnum = X_train.shape[1]\n",
    "    full_x = np.array(False)\n",
    "    allowed_nums = {}\n",
    "    for i in range(maxcolsnum):\n",
    "        allowed_nums[i] = True\n",
    "    actual_nums = []\n",
    "    actual_vars = []\n",
    "    terminate_early = False\n",
    "    y = y_train\n",
    "    for i in range(maxcolsnum):\n",
    "        # Reset boolean and pval_list\n",
    "        terminate_early = False\n",
    "        pval_list = {}\n",
    "        for j in range(maxcolsnum):\n",
    "            if allowed_nums[j] == True:\n",
    "                # Need to reshape to single column instead of a long array for concating properly\n",
    "                jth_x = X_train[:,j].reshape(-1,1)\n",
    "                print(\"i is \" + str(i))\n",
    "                print(\"j is \" + str(j))\n",
    "                print(\"Jth_x:\")\n",
    "                print(jth_x.shape)\n",
    "                print(\"Full_x:\")\n",
    "                print(full_x.shape)\n",
    "                print(full_x.any())\n",
    "                if full_x.any():\n",
    "                    iter_x = np.concatenate((full_x, jth_x), axis=1)\n",
    "                else:\n",
    "                    iter_x = jth_x\n",
    "                regressor_OLS = sm.Logit(y_train, iter_x).fit()\n",
    "                # print(\"p value for column number: \" + str(i))\n",
    "                # print(regressor_OLS.pvalues[0])\n",
    "                pval_list[j] = max(regressor_OLS.pvalues)\n",
    "                # Special condition where all the features have p values of 0, directly use these variables for training\n",
    "                if max(regressor_OLS.pvalues) == 0:\n",
    "                    if full_x.any():\n",
    "                        full_x = np.concatenate((full_x, jth_x), axis=1)\n",
    "                        allowed_nums[j] = False\n",
    "                        actual_nums.append(j)\n",
    "                        print(\"Features all have p value of 0, using feature number \" + str(j))\n",
    "                    else:\n",
    "                        full_x = jth_x\n",
    "                        allowed_nums[j] = False\n",
    "                        actual_nums.append(j)\n",
    "                        print(\"First model trained using feature number \" + str(j) + \" with p value of 0\")\n",
    "                        print(\"Full X:\")\n",
    "                        print(full_x.shape)\n",
    "                    terminate_early = True\n",
    "                    break\n",
    "            else:\n",
    "                continue\n",
    "        if i > 0 and terminate_early == False:\n",
    "            print(\"Getting new model with min p-values with \" + str(len(actual_nums)) + \" variables.\")\n",
    "            max_pval_col = min(pval_list.items(), key=operator.itemgetter(1))[0]\n",
    "            max_pval = pval_list[max_pval_col]\n",
    "            # Need to reshape to single column instead of a long array for concating properly\n",
    "            jth_x = X_train[:,max_pval_col].reshape(-1,1)\n",
    "            if max_pval < sig_level:\n",
    "                if full_x.any():\n",
    "                    full_x = np.concatenate((full_x, jth_x), axis=1)\n",
    "                    allowed_nums[max_pval_col] = False\n",
    "                    actual_nums.append(max_pval_col)\n",
    "                    print(\"New model trained using feature number \" + str(max_pval_col) + \" with lowest p values of \" + str(max_pval))\n",
    "                else:\n",
    "                    full_x = jth_x\n",
    "                    allowed_nums[max_pval_col] = False\n",
    "                    actual_nums.append(max_pval_col)\n",
    "                    print(\"First model trained using feature number \" + str(max_pval_col) + \" with lowest p values of \" + str(max_pval))\n",
    "            else:\n",
    "                print(\"TERMINATING AS best model trained using feature number \" + str(max_pval_col) + \" with high p value of \" + str(max_pval) + \" above significance level: \" + str(sig_level))\n",
    "                break\n",
    "\n",
    "\n",
    "    for k in actual_nums:\n",
    "        actual_vars.append(colnames[k])\n",
    "    print('Final variables selected:')\n",
    "    print(actual_vars)\n",
    "    \n",
    "    return actual_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>16783</td>\n",
       "      <td>28150.0</td>\n",
       "      <td>-1.217577</td>\n",
       "      <td>0.341533</td>\n",
       "      <td>-0.547189</td>\n",
       "      <td>-3.435700</td>\n",
       "      <td>2.068065</td>\n",
       "      <td>2.998467</td>\n",
       "      <td>0.075432</td>\n",
       "      <td>1.358111</td>\n",
       "      <td>0.888721</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.169483</td>\n",
       "      <td>-0.643372</td>\n",
       "      <td>-0.059014</td>\n",
       "      <td>0.970979</td>\n",
       "      <td>0.492970</td>\n",
       "      <td>-1.059613</td>\n",
       "      <td>0.221740</td>\n",
       "      <td>0.093697</td>\n",
       "      <td>57.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>282318</td>\n",
       "      <td>170810.0</td>\n",
       "      <td>1.398705</td>\n",
       "      <td>-0.711496</td>\n",
       "      <td>-2.457786</td>\n",
       "      <td>1.102918</td>\n",
       "      <td>0.082091</td>\n",
       "      <td>-1.274653</td>\n",
       "      <td>0.751314</td>\n",
       "      <td>-0.407527</td>\n",
       "      <td>0.849234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010116</td>\n",
       "      <td>-0.413077</td>\n",
       "      <td>-0.237815</td>\n",
       "      <td>-0.274194</td>\n",
       "      <td>0.078540</td>\n",
       "      <td>-0.321235</td>\n",
       "      <td>-0.044917</td>\n",
       "      <td>0.048623</td>\n",
       "      <td>333.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133376</td>\n",
       "      <td>80358.0</td>\n",
       "      <td>-1.293951</td>\n",
       "      <td>-0.014951</td>\n",
       "      <td>1.810928</td>\n",
       "      <td>-0.091622</td>\n",
       "      <td>1.610843</td>\n",
       "      <td>1.649785</td>\n",
       "      <td>-0.092683</td>\n",
       "      <td>0.740887</td>\n",
       "      <td>-0.611296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037383</td>\n",
       "      <td>0.173010</td>\n",
       "      <td>-0.072245</td>\n",
       "      <td>-1.286169</td>\n",
       "      <td>0.119253</td>\n",
       "      <td>0.430603</td>\n",
       "      <td>0.062277</td>\n",
       "      <td>0.047626</td>\n",
       "      <td>14.49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>243319</td>\n",
       "      <td>151884.0</td>\n",
       "      <td>0.093319</td>\n",
       "      <td>0.977059</td>\n",
       "      <td>-0.331880</td>\n",
       "      <td>-0.624988</td>\n",
       "      <td>0.888892</td>\n",
       "      <td>-0.592453</td>\n",
       "      <td>0.865697</td>\n",
       "      <td>0.036681</td>\n",
       "      <td>-0.291863</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.283002</td>\n",
       "      <td>-0.711688</td>\n",
       "      <td>0.102199</td>\n",
       "      <td>0.656228</td>\n",
       "      <td>-0.473777</td>\n",
       "      <td>0.087180</td>\n",
       "      <td>0.217483</td>\n",
       "      <td>0.075203</td>\n",
       "      <td>3.59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8009</td>\n",
       "      <td>10993.0</td>\n",
       "      <td>1.308139</td>\n",
       "      <td>-0.107937</td>\n",
       "      <td>0.162637</td>\n",
       "      <td>-0.191696</td>\n",
       "      <td>0.081348</td>\n",
       "      <td>0.489166</td>\n",
       "      <td>-0.549243</td>\n",
       "      <td>0.040426</td>\n",
       "      <td>1.559606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120407</td>\n",
       "      <td>-0.123271</td>\n",
       "      <td>-0.251762</td>\n",
       "      <td>-1.362802</td>\n",
       "      <td>0.412063</td>\n",
       "      <td>1.118680</td>\n",
       "      <td>-0.095771</td>\n",
       "      <td>-0.019720</td>\n",
       "      <td>24.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "16783    28150.0 -1.217577  0.341533 -0.547189 -3.435700  2.068065  2.998467   \n",
       "282318  170810.0  1.398705 -0.711496 -2.457786  1.102918  0.082091 -1.274653   \n",
       "133376   80358.0 -1.293951 -0.014951  1.810928 -0.091622  1.610843  1.649785   \n",
       "243319  151884.0  0.093319  0.977059 -0.331880 -0.624988  0.888892 -0.592453   \n",
       "8009     10993.0  1.308139 -0.107937  0.162637 -0.191696  0.081348  0.489166   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "16783   0.075432  1.358111  0.888721  ... -0.169483 -0.643372 -0.059014   \n",
       "282318  0.751314 -0.407527  0.849234  ...  0.010116 -0.413077 -0.237815   \n",
       "133376 -0.092683  0.740887 -0.611296  ...  0.037383  0.173010 -0.072245   \n",
       "243319  0.865697  0.036681 -0.291863  ... -0.283002 -0.711688  0.102199   \n",
       "8009   -0.549243  0.040426  1.559606  ... -0.120407 -0.123271 -0.251762   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "16783   0.970979  0.492970 -1.059613  0.221740  0.093697   57.61      0  \n",
       "282318 -0.274194  0.078540 -0.321235 -0.044917  0.048623  333.77      0  \n",
       "133376 -1.286169  0.119253  0.430603  0.062277  0.047626   14.49      0  \n",
       "243319  0.656228 -0.473777  0.087180  0.217483  0.075203    3.59      0  \n",
       "8009   -1.362802  0.412063  1.118680 -0.095771 -0.019720   24.95      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading in CSV\n",
    "df = pd.read_csv('creditcard.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9',\n",
       "       'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18',\n",
       "       'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27',\n",
       "       'V28', 'Amount', 'Class'], dtype=object)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']\n",
      "SMOTE Oversampling selected..\n",
      "Number of Xs and Ys for: SMOTE\n",
      "[(0, 227451), (1, 227451)]\n",
      "Oversampling is complete!\n",
      "i is 0\n",
      "j is 0\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "()\n",
      "False\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.575659\n",
      "         Iterations 7\n",
      "First model trained using feature number 0 with p value of 0\n",
      "Full X:\n",
      "(454902, 1)\n",
      "i is 1\n",
      "j is 1\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 1)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.511984\n",
      "         Iterations 7\n",
      "Features all have p value of 0, using feature number 1\n",
      "i is 2\n",
      "j is 2\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 2)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.449991\n",
      "         Iterations 8\n",
      "Features all have p value of 0, using feature number 2\n",
      "i is 3\n",
      "j is 3\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 3)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.421980\n",
      "         Iterations 8\n",
      "Features all have p value of 0, using feature number 3\n",
      "i is 4\n",
      "j is 4\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 4)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.420646\n",
      "         Iterations 9\n",
      "i is 4\n",
      "j is 5\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 4)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.420671\n",
      "         Iterations 8\n",
      "i is 4\n",
      "j is 6\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 4)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.415849\n",
      "         Iterations 9\n",
      "Features all have p value of 0, using feature number 6\n",
      "i is 5\n",
      "j is 4\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 5)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.414867\n",
      "         Iterations 9\n",
      "i is 5\n",
      "j is 5\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 5)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.414683\n",
      "         Iterations 9\n",
      "i is 5\n",
      "j is 7\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 5)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.415818\n",
      "         Iterations 9\n",
      "i is 5\n",
      "j is 8\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 5)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.413082\n",
      "         Iterations 9\n",
      "Features all have p value of 0, using feature number 8\n",
      "i is 6\n",
      "j is 4\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412208\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 5\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412131\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 7\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412956\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 9\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.401105\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 10\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.405744\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 11\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.399247\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412972\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 13\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.389202\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.413081\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 15\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.409397\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 16\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.409595\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 17\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412682\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 18\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.413033\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 19\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.413021\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 20\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412455\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 21\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.413071\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 22\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.413012\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 23\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412947\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 24\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412856\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 25\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412991\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 26\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412869\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 27\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412932\n",
      "         Iterations 9\n",
      "i is 6\n",
      "j is 28\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 6)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.377774\n",
      "         Iterations 9\n",
      "Getting new model with min p-values with 6 variables.\n",
      "New model trained using feature number 15 with lowest p values of 3.3043879290976254e-256\n",
      "i is 7\n",
      "j is 4\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.409168\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 5\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408481\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 7\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.409212\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 9\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.399609\n",
      "         Iterations 10\n",
      "i is 7\n",
      "j is 10\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.403130\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 11\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.397863\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.409260\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 13\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.387815\n",
      "         Iterations 10\n",
      "i is 7\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.409383\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 16\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408149\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 17\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.409384\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 18\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.409049\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 19\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.409380\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 20\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.408900\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 21\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.409393\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 22\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.409299\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 23\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.409223\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 24\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.409093\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 25\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.409289\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 26\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.409206\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 27\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.409263\n",
      "         Iterations 9\n",
      "i is 7\n",
      "j is 28\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 7)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.368317\n",
      "         Iterations 9\n",
      "Getting new model with min p-values with 7 variables.\n",
      "New model trained using feature number 28 with lowest p values of 4.8685446526612056e-247\n",
      "i is 8\n",
      "j is 4\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 8)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.345864\n",
      "         Iterations 10\n",
      "Features all have p value of 0, using feature number 4\n",
      "i is 9\n",
      "j is 5\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 9)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.343719\n",
      "         Iterations 10\n",
      "Features all have p value of 0, using feature number 5\n",
      "i is 10\n",
      "j is 7\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 10)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.337722\n",
      "         Iterations 10\n",
      "Features all have p value of 0, using feature number 7\n",
      "i is 11\n",
      "j is 9\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 11)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.289401\n",
      "         Iterations 10\n",
      "i is 11\n",
      "j is 10\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 11)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.322335\n",
      "         Iterations 10\n",
      "Features all have p value of 0, using feature number 10\n",
      "i is 12\n",
      "j is 9\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 12)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.283913\n",
      "         Iterations 10\n",
      "i is 12\n",
      "j is 11\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 12)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.303512\n",
      "         Iterations 10\n",
      "i is 12\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 12)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.322334\n",
      "         Iterations 10\n",
      "i is 12\n",
      "j is 13\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 12)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.290478\n",
      "         Iterations 10\n",
      "Features all have p value of 0, using feature number 13\n",
      "i is 13\n",
      "j is 9\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 13)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.270786\n",
      "         Iterations 11\n",
      "i is 13\n",
      "j is 11\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 13)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274586\n",
      "         Iterations 10\n",
      "Features all have p value of 0, using feature number 11\n",
      "i is 14\n",
      "j is 9\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 14)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.252616\n",
      "         Iterations 11\n",
      "i is 14\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 14)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274419\n",
      "         Iterations 10\n",
      "i is 14\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 14)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274452\n",
      "         Iterations 10\n",
      "i is 14\n",
      "j is 16\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 14)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.269045\n",
      "         Iterations 12\n",
      "i is 14\n",
      "j is 17\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 14)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274365\n",
      "         Iterations 10\n",
      "i is 14\n",
      "j is 18\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 14)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273925\n",
      "         Iterations 10\n",
      "i is 14\n",
      "j is 19\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 14)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.260399\n",
      "         Iterations 11\n",
      "Features all have p value of 0, using feature number 19\n",
      "i is 15\n",
      "j is 9\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 15)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.235619\n",
      "         Iterations 11\n",
      "Features all have p value of 0, using feature number 9\n",
      "i is 16\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 16)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.235597\n",
      "         Iterations 11\n",
      "i is 16\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 16)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.235577\n",
      "         Iterations 11\n",
      "i is 16\n",
      "j is 16\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 16)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.221423\n",
      "         Iterations 13\n",
      "Features all have p value of 0, using feature number 16\n",
      "i is 17\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 17)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.221390\n",
      "         Iterations 13\n",
      "i is 17\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 17)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.221296\n",
      "         Iterations 13\n",
      "i is 17\n",
      "j is 17\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 17)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.218277\n",
      "         Iterations 14\n",
      "i is 17\n",
      "j is 18\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 17)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.219465\n",
      "         Iterations 13\n",
      "Features all have p value of 0, using feature number 18\n",
      "i is 18\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 18)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.219452\n",
      "         Iterations 13\n",
      "i is 18\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 18)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.219423\n",
      "         Iterations 13\n",
      "i is 18\n",
      "j is 17\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 18)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.217393\n",
      "         Iterations 14\n",
      "i is 18\n",
      "j is 20\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 18)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.207206\n",
      "         Iterations 13\n",
      "Features all have p value of 0, using feature number 20\n",
      "i is 19\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 19)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.207179\n",
      "         Iterations 13\n",
      "i is 19\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 19)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.207139\n",
      "         Iterations 13\n",
      "i is 19\n",
      "j is 17\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 19)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.202662\n",
      "         Iterations 15\n",
      "i is 19\n",
      "j is 21\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 19)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.205661\n",
      "         Iterations 13\n",
      "i is 19\n",
      "j is 22\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 19)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.188988\n",
      "         Iterations 14\n",
      "Features all have p value of 0, using feature number 22\n",
      "i is 20\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 20)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.188918\n",
      "         Iterations 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i is 20\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 20)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.188982\n",
      "         Iterations 14\n",
      "i is 20\n",
      "j is 17\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 20)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.186851\n",
      "         Iterations 16\n",
      "i is 20\n",
      "j is 21\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 20)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.185092\n",
      "         Iterations 14\n",
      "Features all have p value of 0, using feature number 21\n",
      "i is 21\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 21)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.185051\n",
      "         Iterations 14\n",
      "i is 21\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 21)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.185081\n",
      "         Iterations 14\n",
      "i is 21\n",
      "j is 17\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 21)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.183236\n",
      "         Iterations 15\n",
      "i is 21\n",
      "j is 23\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 21)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.185088\n",
      "         Iterations 14\n",
      "i is 21\n",
      "j is 24\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 21)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.179446\n",
      "         Iterations 14\n",
      "Features all have p value of 0, using feature number 24\n",
      "i is 22\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 22)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.179426\n",
      "         Iterations 14\n",
      "i is 22\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 22)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.179424\n",
      "         Iterations 14\n",
      "i is 22\n",
      "j is 17\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 22)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.178322\n",
      "         Iterations 16\n",
      "i is 22\n",
      "j is 23\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 22)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.179443\n",
      "         Iterations 14\n",
      "i is 22\n",
      "j is 25\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 22)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.178977\n",
      "         Iterations 14\n",
      "i is 22\n",
      "j is 26\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 22)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.176402\n",
      "         Iterations 14\n",
      "Features all have p value of 0, using feature number 26\n",
      "i is 23\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 23)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.176377\n",
      "         Iterations 14\n",
      "i is 23\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 23)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.176361\n",
      "         Iterations 14\n",
      "i is 23\n",
      "j is 17\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 23)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.175375\n",
      "         Iterations 16\n",
      "i is 23\n",
      "j is 23\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 23)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.176402\n",
      "         Iterations 14\n",
      "i is 23\n",
      "j is 25\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 23)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.176116\n",
      "         Iterations 14\n",
      "i is 23\n",
      "j is 27\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 23)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.173919\n",
      "         Iterations 15\n",
      "Features all have p value of 0, using feature number 27\n",
      "i is 24\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 24)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.173904\n",
      "         Iterations 15\n",
      "i is 24\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 24)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.173892\n",
      "         Iterations 15\n",
      "i is 24\n",
      "j is 17\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 24)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.172708\n",
      "         Iterations 16\n",
      "i is 24\n",
      "j is 23\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 24)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.173918\n",
      "         Iterations 15\n",
      "i is 24\n",
      "j is 25\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 24)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.173601\n",
      "         Iterations 14\n",
      "Getting new model with min p-values with 24 variables.\n",
      "New model trained using feature number 17 with lowest p values of 3.498035268213619e-200\n",
      "i is 25\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 25)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.172690\n",
      "         Iterations 16\n",
      "i is 25\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 25)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.172702\n",
      "         Iterations 16\n",
      "i is 25\n",
      "j is 23\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 25)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.172703\n",
      "         Iterations 16\n",
      "i is 25\n",
      "j is 25\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 25)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.172413\n",
      "         Iterations 16\n",
      "Getting new model with min p-values with 25 variables.\n",
      "New model trained using feature number 25 with lowest p values of 5.223961749743435e-59\n",
      "i is 26\n",
      "j is 12\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 26)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.172393\n",
      "         Iterations 16\n",
      "i is 26\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 26)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.172406\n",
      "         Iterations 16\n",
      "i is 26\n",
      "j is 23\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 26)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.172410\n",
      "         Iterations 16\n",
      "Getting new model with min p-values with 26 variables.\n",
      "New model trained using feature number 12 with lowest p values of 1.854060501607652e-05\n",
      "i is 27\n",
      "j is 14\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 27)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.172384\n",
      "         Iterations 16\n",
      "i is 27\n",
      "j is 23\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 27)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.172390\n",
      "         Iterations 16\n",
      "Getting new model with min p-values with 27 variables.\n",
      "New model trained using feature number 14 with lowest p values of 0.00560654338986908\n",
      "i is 28\n",
      "j is 23\n",
      "Jth_x:\n",
      "(454902, 1)\n",
      "Full_x:\n",
      "(454902, 28)\n",
      "True\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.172382\n",
      "         Iterations 16\n",
      "Getting new model with min p-values with 28 variables.\n",
      "TERMINATING AS best model trained using feature number 23 with high p value of 0.15750441461367337 above significance level: 0.05\n",
      "Final variables selected:\n",
      "['V1', 'V2', 'V3', 'V4', 'V7', 'V9', 'V16', 'Amount', 'V5', 'V6', 'V8', 'V11', 'V14', 'V12', 'V20', 'V10', 'V17', 'V19', 'V21', 'V23', 'V22', 'V25', 'V27', 'V28', 'V18', 'V26', 'V13', 'V15']\n"
     ]
    }
   ],
   "source": [
    "finalcolstouse = forwardselection(df,0.2,'Class','Time','smote')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Selection without comments and with feature name chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "import statsmodels.discrete.discrete_model as sm\n",
    "\n",
    "def forwardselection(df,testratio,response,removelist,sampling):\n",
    "    if isinstance(removelist, str) == True:\n",
    "        temp_str = removelist\n",
    "        internallist = []\n",
    "        internallist.append(temp_str)\n",
    "    internallist = removelist\n",
    "    internallist.append(temp_str)\n",
    "    X = df.drop(internallist, axis=1)\n",
    "    y = df[response]\n",
    "    # Get list of column names\n",
    "    colnames = list(X.columns.values)\n",
    "    print(colnames)\n",
    "    \n",
    "    # Start of train-test split and oversampling (if relevant)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testratio, random_state=42)\n",
    "    if sampling.lower() == 'smote':\n",
    "        print(\"SMOTE Oversampling selected..\")\n",
    "        X_train, y_train = SMOTE().fit_resample(X_train, y_train)\n",
    "        # train test split keeps X_test and y_test as pd series, oversampler converts X_train, y_train to numpy\n",
    "        # Convert all to numpy array for XGBoost to not have bugs\n",
    "        X_test = X_test.values\n",
    "        y_test = y_test.values\n",
    "        print(\"Number of Xs and Ys for: \" + str(sampling.upper()))\n",
    "        print(sorted(Counter(y_train).items()))\n",
    "        print(\"Oversampling is complete!\")\n",
    "    elif sampling.lower() == 'naive':\n",
    "        print(\"Naive Oversampling selected..\")\n",
    "        ros = RandomOverSampler(random_state=42)\n",
    "        X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "        # train test split keeps X_test and y_test as pd series, oversampler converts X_train, y_train to numpy\n",
    "        # Convert all to numpy array for XGBoost to not have bugs\n",
    "        X_test = X_test.values\n",
    "        y_test = y_test.values\n",
    "        print(\"Number of Xs and Ys for: \" + str(sampling.upper()))\n",
    "        print(sorted(Counter(y_train).items()))\n",
    "        print(\"Oversampling is complete!\")\n",
    "\n",
    "\n",
    "    # Total features to select = k\n",
    "    # In each iteration, the current set of n features is concatenated with a new feature not inside current set\n",
    "    # It is then sent for training with the logistic regression\n",
    "    # The model performance for each feature + current features is evaluated by its highest p value (worst feature)\n",
    "    # All highest p values of all feature addition to n features (k-n iterations) are put into a dictionary\n",
    "    # Next, the lowest p value out of all the iterations (for n features + 1) is chosen for evaluation\n",
    "    # Set significance level, which is compared to the lowest p value of the best model in the current training iteration\n",
    "    # If best model in current training iteration of n vars has any vars with p value > sig level, then the model training stops\n",
    "    # Because all the different models are worse or equally bad as the current best model, we can terminate selection process\n",
    "    # If not, repeat this iteration with now n+1 features and k-n-1 iterations\n",
    "    sig_level = 0.05\n",
    "\n",
    "    maxcolsnum = X_train.shape[1]\n",
    "    full_x = np.array(False)\n",
    "    allowed_nums = {}\n",
    "    for i in range(maxcolsnum):\n",
    "        allowed_nums[i] = True\n",
    "    actual_nums = []\n",
    "    actual_vars = []\n",
    "    terminate_early = False\n",
    "    y = y_train\n",
    "    for i in range(maxcolsnum):\n",
    "        # Reset boolean and pval_list\n",
    "        terminate_early = False\n",
    "        pval_list = {}\n",
    "        for j in range(maxcolsnum):\n",
    "            if allowed_nums[j] == True:\n",
    "                # Need to reshape to single column instead of a long array for concating properly\n",
    "                jth_x = X_train[:,j].reshape(-1,1)\n",
    "                if full_x.any():\n",
    "                    iter_x = np.concatenate((full_x, jth_x), axis=1)\n",
    "                else:\n",
    "                    iter_x = jth_x\n",
    "                regressor_OLS = sm.Logit(y_train, iter_x).fit(disp=0)\n",
    "                pval_list[j] = max(regressor_OLS.pvalues)\n",
    "                # Special condition where all the features have p values of 0, directly use these variables for training\n",
    "                if max(regressor_OLS.pvalues) == 0:\n",
    "                    if full_x.any():\n",
    "                        full_x = np.concatenate((full_x, jth_x), axis=1)\n",
    "                        allowed_nums[j] = False\n",
    "                        actual_nums.append(j)\n",
    "                        print(\"Features all have p value of 0, using feature: [\" + str(colnames[j]) + \"]\")\n",
    "                    else:\n",
    "                        full_x = jth_x\n",
    "                        allowed_nums[j] = False\n",
    "                        actual_nums.append(j)\n",
    "                        print(\"First model trained using feature: [\" + str(colnames[j]) + \"] with p value of 0\")\n",
    "                    terminate_early = True\n",
    "                    break\n",
    "            else:\n",
    "                continue\n",
    "        if i > 0 and terminate_early == False:\n",
    "            print(\"Building new model with lowest p-values with \" + str(len(actual_nums)) + \" variables.\")\n",
    "            max_pval_col = min(pval_list.items(), key=operator.itemgetter(1))[0]\n",
    "            max_pval = pval_list[max_pval_col]\n",
    "            # Need to reshape to single column instead of a long array for concating properly\n",
    "            jth_x = X_train[:,max_pval_col].reshape(-1,1)\n",
    "            if max_pval < sig_level:\n",
    "                if full_x.any():\n",
    "                    full_x = np.concatenate((full_x, jth_x), axis=1)\n",
    "                    allowed_nums[max_pval_col] = False\n",
    "                    actual_nums.append(max_pval_col)\n",
    "                    print(\"New model trained using feature: [\" + str(colnames[max_pval_col]) + \"] with lowest p values of \" + str(max_pval))\n",
    "                else:\n",
    "                    full_x = jth_x\n",
    "                    allowed_nums[max_pval_col] = False\n",
    "                    actual_nums.append(max_pval_col)\n",
    "                    print(\"First model trained using feature: [\" + str(colnames[max_pval_col]) + \"] with lowest p values of \" + str(max_pval))\n",
    "            else:\n",
    "                print(\"TERMINATING AS best model trained using feature: [\" + str(colnames[max_pval_col]) + \"] with high p value of \" + str(max_pval) + \" above significance level: \" + str(sig_level))\n",
    "                break\n",
    "\n",
    "\n",
    "    for k in actual_nums:\n",
    "        actual_vars.append(colnames[k])\n",
    "    print('Final variables selected:')\n",
    "    print(actual_vars)\n",
    "    \n",
    "    return actual_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']\n",
      "Naive Oversampling selected..\n",
      "Number of Xs and Ys for: NAIVE\n",
      "[(0, 255880), (1, 255880)]\n",
      "Oversampling is complete!\n",
      "First model trained using feature: [V1] with p value of 0\n",
      "Features all have p value of 0, using feature: [V2]\n",
      "Features all have p value of 0, using feature: [V3]\n",
      "Features all have p value of 0, using feature: [V4]\n",
      "Features all have p value of 0, using feature: [V6]\n",
      "Features all have p value of 0, using feature: [V7]\n",
      "Features all have p value of 0, using feature: [V17]\n",
      "Building new model with lowest p-values with 7 variables.\n",
      "New model trained using feature: [V9] with lowest p values of 1.3499052620827247e-291\n",
      "Building new model with lowest p-values with 8 variables.\n",
      "New model trained using feature: [V11] with lowest p values of 7.468764810312311e-186\n",
      "Building new model with lowest p-values with 9 variables.\n",
      "New model trained using feature: [V8] with lowest p values of 1.7557655661627995e-134\n",
      "Building new model with lowest p-values with 10 variables.\n",
      "New model trained using feature: [V16] with lowest p values of 2.025681486168209e-111\n",
      "Building new model with lowest p-values with 11 variables.\n",
      "New model trained using feature: [V19] with lowest p values of 5.369924262646178e-88\n",
      "Building new model with lowest p-values with 12 variables.\n",
      "New model trained using feature: [V10] with lowest p values of 1.7291020174766805e-66\n",
      "Building new model with lowest p-values with 13 variables.\n",
      "New model trained using feature: [Amount] with lowest p values of 2.8652322063445345e-133\n",
      "Building new model with lowest p-values with 14 variables.\n",
      "New model trained using feature: [V20] with lowest p values of 3.224049638313465e-228\n",
      "Building new model with lowest p-values with 15 variables.\n",
      "New model trained using feature: [V12] with lowest p values of 3.1094354925846875e-265\n",
      "Building new model with lowest p-values with 16 variables.\n",
      "New model trained using feature: [V27] with lowest p values of 6.177133414790537e-293\n",
      "Building new model with lowest p-values with 17 variables.\n",
      "New model trained using feature: [V21] with lowest p values of 1.9789072567592236e-259\n",
      "Building new model with lowest p-values with 18 variables.\n",
      "New model trained using feature: [V22] with lowest p values of 1.3134325689319603e-257\n",
      "Building new model with lowest p-values with 19 variables.\n",
      "New model trained using feature: [V23] with lowest p values of 1.275919205059183e-207\n",
      "Building new model with lowest p-values with 20 variables.\n",
      "New model trained using feature: [V25] with lowest p values of 1.2099032360079392e-214\n",
      "Building new model with lowest p-values with 21 variables.\n",
      "New model trained using feature: [V14] with lowest p values of 6.771657419998585e-201\n",
      "Features all have p value of 0, using feature: [V5]\n",
      "Features all have p value of 0, using feature: [V28]\n",
      "Building new model with lowest p-values with 24 variables.\n",
      "New model trained using feature: [V26] with lowest p values of 3.6214870764610725e-139\n",
      "Building new model with lowest p-values with 25 variables.\n",
      "New model trained using feature: [V15] with lowest p values of 1.8987394782697368e-63\n",
      "Building new model with lowest p-values with 26 variables.\n",
      "New model trained using feature: [V24] with lowest p values of 3.634583487921335e-39\n",
      "Building new model with lowest p-values with 27 variables.\n",
      "New model trained using feature: [V13] with lowest p values of 1.7532606179068094e-12\n",
      "Building new model with lowest p-values with 28 variables.\n",
      "New model trained using feature: [V18] with lowest p values of 6.67651993764899e-08\n",
      "Final variables selected:\n",
      "['V1', 'V2', 'V3', 'V4', 'V6', 'V7', 'V17', 'V9', 'V11', 'V8', 'V16', 'V19', 'V10', 'Amount', 'V20', 'V12', 'V27', 'V21', 'V22', 'V23', 'V25', 'V14', 'V5', 'V28', 'V26', 'V15', 'V24', 'V13', 'V18']\n"
     ]
    }
   ],
   "source": [
    "finalcolstouse = forwardselection(df,0.1,'Class','Time','naive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use existing model pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalcolstouse = ['V1', 'V2', 'V3', 'V4', 'V6', 'V7', 'V17', 'V9', 'V11', 'V8', 'V16', 'V19', 'V10', 'Amount', 'V20', 'V12', 'V27', 'V21', 'V22', 'V23', 'V25', 'V14', 'V5', 'V28', 'V26', 'V15', 'V24', 'V13', 'V18']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:111: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oversampling is complete!\n",
      "[0]\tvalidation_0-error:0.024964\tvalidation_1-error:0.011025\n",
      "[5]\tvalidation_0-error:0.016786\tvalidation_1-error:0.007321\n",
      "[10]\tvalidation_0-error:0.009457\tvalidation_1-error:0.005003\n",
      "[15]\tvalidation_0-error:0.006373\tvalidation_1-error:0.003652\n",
      "[20]\tvalidation_0-error:0.00115\tvalidation_1-error:0.002949\n",
      "[25]\tvalidation_0-error:0.000873\tvalidation_1-error:0.002458\n",
      "[30]\tvalidation_0-error:0.000653\tvalidation_1-error:0.001949\n",
      "[35]\tvalidation_0-error:0.000523\tvalidation_1-error:0.00165\n",
      "[40]\tvalidation_0-error:0.000444\tvalidation_1-error:0.001475\n",
      "[45]\tvalidation_0-error:0.000393\tvalidation_1-error:0.001352\n",
      "[50]\tvalidation_0-error:0.000339\tvalidation_1-error:0.001211\n",
      "[55]\tvalidation_0-error:0.000314\tvalidation_1-error:0.001159\n",
      "[60]\tvalidation_0-error:0.000275\tvalidation_1-error:0.001036\n",
      "[65]\tvalidation_0-error:0.000244\tvalidation_1-error:0.00093\n",
      "[70]\tvalidation_0-error:0.000167\tvalidation_1-error:0.000737\n",
      "[75]\tvalidation_0-error:0.00013\tvalidation_1-error:0.00072\n",
      "[80]\tvalidation_0-error:0.000103\tvalidation_1-error:0.000667\n",
      "[85]\tvalidation_0-error:8.4e-05\tvalidation_1-error:0.000614\n",
      "[90]\tvalidation_0-error:7.3e-05\tvalidation_1-error:0.000614\n",
      "[95]\tvalidation_0-error:7.7e-05\tvalidation_1-error:0.000597\n",
      "[99]\tvalidation_0-error:6.8e-05\tvalidation_1-error:0.000597\n",
      "[[56854    14]\n",
      " [   20    74]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.999403110845827\n",
      "Sensitivity: 0.7872340425531915\n",
      "Specificity: 0.9997538158542589\n",
      "Precision: 0.8409090909090909\n",
      "f1 score: 0.8131868131868133\n",
      "AUC value is: 0.8934939292037252\n",
      "Model classification metrics have finished calculating!\n",
      "Model fitting and results are complete!\n",
      "Accuracy with all fraud results is 95.9349593495935%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using train test split number = 41 for all sampling\n",
    "\n",
    "# finalcolstouse is list of features that are significant (p < 0.05) for linear regression\n",
    "# modelpipeline.run_model(self, df, varlist, response, testratio, standardize, sampletype, modelname, text, CV)\n",
    "results = modelpipeline.run_model(df, finalcolstouse, 'Class', 0.2, True, 'naive', 'XGBoost', 'XGBoost with forward linear selection', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:111: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oversampling is complete!\n",
      "[0]\tvalidation_0-error:0.027048\tvalidation_1-error:0.03332\n",
      "[5]\tvalidation_0-error:0.012141\tvalidation_1-error:0.015344\n",
      "[10]\tvalidation_0-error:0.006641\tvalidation_1-error:0.009146\n",
      "[15]\tvalidation_0-error:0.002801\tvalidation_1-error:0.006092\n",
      "[20]\tvalidation_0-error:0.002238\tvalidation_1-error:0.004582\n",
      "[25]\tvalidation_0-error:0.001908\tvalidation_1-error:0.003739\n",
      "[30]\tvalidation_0-error:0.001572\tvalidation_1-error:0.003318\n",
      "[35]\tvalidation_0-error:0.001211\tvalidation_1-error:0.002897\n",
      "[40]\tvalidation_0-error:0.001079\tvalidation_1-error:0.002686\n",
      "[45]\tvalidation_0-error:0.000906\tvalidation_1-error:0.002458\n",
      "[50]\tvalidation_0-error:0.0008\tvalidation_1-error:0.002019\n",
      "[55]\tvalidation_0-error:0.000708\tvalidation_1-error:0.001843\n",
      "[60]\tvalidation_0-error:0.000598\tvalidation_1-error:0.00158\n",
      "[65]\tvalidation_0-error:0.000481\tvalidation_1-error:0.001422\n",
      "[70]\tvalidation_0-error:0.000411\tvalidation_1-error:0.001317\n",
      "[75]\tvalidation_0-error:0.000361\tvalidation_1-error:0.001124\n",
      "[80]\tvalidation_0-error:0.000277\tvalidation_1-error:0.000966\n",
      "[85]\tvalidation_0-error:0.000231\tvalidation_1-error:0.000895\n",
      "[90]\tvalidation_0-error:0.000187\tvalidation_1-error:0.00079\n",
      "[95]\tvalidation_0-error:0.000167\tvalidation_1-error:0.00065\n",
      "[99]\tvalidation_0-error:0.000143\tvalidation_1-error:0.000562\n",
      "[[56843    22]\n",
      " [   10    87]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9994382219725431\n",
      "Sensitivity: 0.8969072164948454\n",
      "Specificity: 0.9996131187901169\n",
      "Precision: 0.7981651376146789\n",
      "f1 score: 0.8446601941747572\n",
      "AUC value is: 0.9482601676424811\n",
      "Model classification metrics have finished calculating!\n",
      "Model fitting and results are complete!\n",
      "Accuracy with all fraud results is 97.96747967479675%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using train test split number = 40 for all sampling\n",
    "\n",
    "# finalcolstouse is list of features that are significant (p < 0.05) for linear regression\n",
    "# modelpipeline.run_model(self, df, varlist, response, testratio, standardize, sampletype, modelname, text, CV)\n",
    "results = modelpipeline.run_model(df, finalcolstouse, 'Class', 0.2, True, 'naive', 'XGBoost', 'XGBoost with forward linear selection', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
